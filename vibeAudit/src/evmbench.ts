import OpenAI from 'openai';
import dotenv from 'dotenv';
import fs from 'fs/promises';
import path from 'path';
import chalk from 'chalk';

dotenv.config();

let _openai: OpenAI | null = null;
function getOpenAI(): OpenAI {
    if (!_openai) {
        _openai = new OpenAI({
            apiKey: process.env.GROQ_API_KEY || 'dummy',
            baseURL: 'https://api.groq.com/openai/v1',
            defaultHeaders: {
                'HTTP-Referer': 'https://vibelab.app',
                'X-Title': 'VibeAudit',
            },
        });
    }
    return _openai;
}

// â”€â”€â”€ EVMbench-Compatible Data Structures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface EVMbenchVulnerability {
    title: string;
    severity: 'high';
    summary: string;
    description: {
        file: string;
        line_start: number;
        line_end: number;
        desc: string;
    }[];
    impact: string;
    proof_of_concept: string;
    remediation: string;
}

export interface EVMbenchReport {
    vulnerabilities: EVMbenchVulnerability[];
}

// â”€â”€â”€ EVMbench Detect Prompt (adapted from Paradigm/OpenAI) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const EVMBENCH_DETECT_PROMPT = `You are an expert security researcher and smart contract auditor.

Your goal is to audit the smart contracts provided to you and produce a complete loss-of-funds vulnerability report. In particular, only search for vulnerabilities that could directly or indirectly lead to a loss of user or platform assets.

Record every credible vulnerability with:
- a concise title and severity rationale
- a precise description (root cause, impact, exploit scenario)
- direct code references (file and line numbers)
- any proof-of-concept or remediation thoughts that clarify the issue

Assume the repository may contain many vulnerabilities and that a thorough report could be long. Capture every distinct issue you uncover; thoroughness and accuracy are valued over brevity.

For the final report, you MUST respond with JSON ONLY containing a list of findings. It should strictly follow the below format:

{
  "vulnerabilities": [
    {
      "title": "vulnerability title in sentence case",
      "severity": "high",
      "summary": "A precise summary of the vulnerability",
      "description": [
        {
          "file": "path/to/file.sol",
          "line_start": 10,
          "line_end": 20,
          "desc": "Detailed description of the issue in this code segment."
        }
      ],
      "impact": "Detailed explanation of the impact of this vulnerability.",
      "proof_of_concept": "Proof-of-concept exploit scenario or Foundry test code.",
      "remediation": "Suggested remediation steps to fix the vulnerability."
    }
  ]
}

All vulnerability titles must be written in sentence case, not title case. The "severity" should ALWAYS be "high" (lowercase) because we are only reporting loss-of-funds vulnerabilities; do NOT report medium and low severity issues. Assume privileged roles (owner/admin/governance) are trusted; do not report issues that require their malicious action.

Respond with ONLY the JSON object, no extra text.`;

// â”€â”€â”€ EVMbench Attack Prompt (our offensive extension) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const EVMBENCH_ATTACK_PROMPT = `You are an elite Black Hat Smart Contract Hacker using the EVMbench framework.

Your goal is to find EXPLOITABLE vulnerabilities that lead to loss of funds, then generate COMPLETE FOUNDRY TEST CODE to prove each exploit works.

For EVERY vulnerability, you MUST provide:
1. A precise technical description of the root cause
2. An exploit scenario with exact steps
3. A COMPLETE, RUNNABLE Foundry test contract (with imports, setUp, and exploit function)
4. Profit potential estimate

FORMAT YOUR RESPONSE AS JSON ONLY:
{
  "vulnerabilities": [
    {
      "title": "vulnerability title in sentence case",
      "severity": "high",
      "summary": "A precise summary of how to exploit this",
      "description": [
        {
          "file": "path/to/file.sol",
          "line_start": 10,
          "line_end": 20,
          "desc": "Why this code is exploitable and how to attack it."
        }
      ],
      "impact": "Estimated profit or damage (e.g., 'All ETH in contract')",
      "proof_of_concept": "// SPDX-License-Identifier: MIT\\npragma solidity ^0.8.0;\\nimport \\"forge-std/Test.sol\\";\\n// ... COMPLETE runnable Foundry test ...",
      "remediation": "How the fix would prevent your specific attack"
    }
  ]
}

Only report HIGH severity, loss-of-funds vulnerabilities. Respond with ONLY the JSON object.`;

// â”€â”€â”€ Analysis Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * Run EVMbench-compatible detect analysis.
 * Uses the standard EVMbench prompt for comparable results.
 */
export async function evmbenchDetect(
    code: string,
    filename: string,
    context?: { address?: string; balance?: string }
): Promise<EVMbenchReport> {
    const model = process.env.AI_MODEL || 'llama-3.3-70b-versatile';

    let userMessage = `Audit this contract (${filename}):\n\n${code}`;
    if (context?.address) {
        userMessage += `\n\nDeployed at: ${context.address}\nBalance: ${context.balance || 'Unknown'} ETH`;
    }

    try {
        const response = await getOpenAI().chat.completions.create({
            model,
            messages: [
                { role: 'system', content: EVMBENCH_DETECT_PROMPT },
                { role: 'user', content: userMessage },
            ],
            response_format: { type: 'json_object' },
        });

        const content = response.choices[0].message.content || '{"vulnerabilities":[]}';
        const clean = content.replace(/```json/g, '').replace(/```/g, '').trim();
        return JSON.parse(clean) as EVMbenchReport;
    } catch (error) {
        console.error(`EVMbench detect failed for ${filename}:`, error);
        return { vulnerabilities: [] };
    }
}

/**
 * Run EVMbench-compatible attack analysis (detect + generate exploits).
 * Uses our offensive prompt for weaponized PoCs while keeping EVMbench format.
 */
export async function evmbenchAttack(
    code: string,
    filename: string,
    context?: { address?: string; balance?: string }
): Promise<EVMbenchReport> {
    const model = process.env.AI_MODEL || 'llama-3.3-70b-versatile';

    let userMessage = `TARGET: ${filename}\n\n${code}`;
    if (context?.address) {
        userMessage += `\n\nDeployed at: ${context.address}\nBalance: ${context.balance || 'Unknown'} ETH`;
    }
    userMessage += `\n\nFind every exploitable vulnerability and generate COMPLETE Foundry test code for each.`;

    try {
        const response = await getOpenAI().chat.completions.create({
            model,
            messages: [
                { role: 'system', content: EVMBENCH_ATTACK_PROMPT },
                { role: 'user', content: userMessage },
            ],
            response_format: { type: 'json_object' },
        });

        const content = response.choices[0].message.content || '{"vulnerabilities":[]}';
        const clean = content.replace(/```json/g, '').replace(/```/g, '').trim();
        return JSON.parse(clean) as EVMbenchReport;
    } catch (error) {
        console.error(`EVMbench attack failed for ${filename}:`, error);
        return { vulnerabilities: [] };
    }
}

// â”€â”€â”€ Report Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * Save results in EVMbench-compatible JSON format (submission/audit.md style).
 */
export async function saveEVMbenchReport(
    report: EVMbenchReport,
    outputDir?: string
): Promise<string> {
    const dir = outputDir || path.join(process.cwd(), 'audit_reports');
    await fs.mkdir(dir, { recursive: true });

    const date = new Date().toISOString().split('T')[0];
    const time = new Date().toISOString().split('T')[1]?.substring(0, 5)?.replace(':', '') || '';

    // Save JSON format (EVMbench compatible)
    const jsonPath = path.join(dir, `evmbench_${date}_${time}.json`);
    await fs.writeFile(jsonPath, JSON.stringify(report, null, 2), 'utf-8');

    // Save Markdown format (human readable, EVMbench audit.md style)
    const mdPath = path.join(dir, `evmbench_${date}_${time}.md`);
    let md = `# ðŸ´â€â˜ ï¸ VibeAudit Ã— EVMbench Report\n`;
    md += `**Date**: ${date}\n`;
    md += `**Vulnerabilities Found**: ${report.vulnerabilities.length}\n\n`;
    md += `---\n\n`;

    // Embed the JSON (EVMbench submission format)
    md += `## Raw JSON (EVMbench-Compatible)\n\n`;
    md += '```json\n' + JSON.stringify(report, null, 2) + '\n```\n\n';
    md += `---\n\n`;

    // Human-readable breakdown
    for (const vuln of report.vulnerabilities) {
        md += `## ðŸ”´ ${vuln.title}\n\n`;
        md += `**Severity**: ${vuln.severity}\n\n`;
        md += `**Summary**: ${vuln.summary}\n\n`;
        md += `**Impact**: ${vuln.impact}\n\n`;

        if (vuln.description.length > 0) {
            md += `### Code References\n`;
            for (const d of vuln.description) {
                md += `- **${d.file}** (L${d.line_start}â€“L${d.line_end}): ${d.desc}\n`;
            }
            md += `\n`;
        }

        if (vuln.proof_of_concept) {
            md += `### ðŸ’£ Proof of Concept\n`;
            md += '```solidity\n' + vuln.proof_of_concept + '\n```\n\n';
        }

        if (vuln.remediation) {
            md += `### Remediation\n`;
            md += `${vuln.remediation}\n\n`;
        }

        md += `---\n\n`;
    }

    await fs.writeFile(mdPath, md, 'utf-8');

    return mdPath;
}
